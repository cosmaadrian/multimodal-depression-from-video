{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import seaborn as sns\n",
    "from pprint import pprint\n",
    "import json\n",
    "from scipy.stats import mode\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_files = glob.glob('../results/dvlog-baseline-model-size-ablation/*.csv')\n",
    "\n",
    "dfs = []\n",
    "for file in result_files:\n",
    "    df = pd.read_csv(file)\n",
    "\n",
    "    # get seconds_per_window\n",
    "    df['seconds_per_window'] = int(file.split(':')[-2].split('-')[3])\n",
    "    df['presence_threshold'] = float(file.split(':')[-2].split('-')[1])\n",
    "    df['num_layers'] = int(file.split(':')[-2].split('-')[5])\n",
    "    df['num_heads'] = int(file.split(':')[-2].split('-')[6][-1:])\n",
    "    df['head_dim'] = int(file.split(':')[-2].split('-')[7][-2:])\n",
    "    df['run_id'] = int(file.split(':')[-2].split('-')[9])\n",
    "    df['filename'] = file.split('/')[-1]\n",
    "    df['evaluator'] = file.split('/')[-1].split(':')[0]\n",
    "\n",
    "    dfs.append(df)\n",
    "\n",
    "dfs = pd.concat(dfs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>f1</th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>auc</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>name</th>\n",
       "      <th>dataset</th>\n",
       "      <th>dataset_kind</th>\n",
       "      <th>model</th>\n",
       "      <th>prediction_kind</th>\n",
       "      <th>...</th>\n",
       "      <th>num_heads</th>\n",
       "      <th>head_dim</th>\n",
       "      <th>run_id</th>\n",
       "      <th>filename</th>\n",
       "      <th>evaluator</th>\n",
       "      <th>modalities</th>\n",
       "      <th>model_args.num_layers</th>\n",
       "      <th>model_args.self_attn_num_heads</th>\n",
       "      <th>model_args.self_attn_dim_head</th>\n",
       "      <th>f1_weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.590476</td>\n",
       "      <td>0.601942</td>\n",
       "      <td>0.579439</td>\n",
       "      <td>0.560962</td>\n",
       "      <td>0.544974</td>\n",
       "      <td>dvlog-baseline-model-size-ablation:pt-0.25-spw...</td>\n",
       "      <td>d-vlog</td>\n",
       "      <td>test</td>\n",
       "      <td>baseline</td>\n",
       "      <td>last</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>temporal-evaluator:dvlog-baseline-model-size-a...</td>\n",
       "      <td>temporal-evaluator</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.743119</td>\n",
       "      <td>0.786408</td>\n",
       "      <td>0.704348</td>\n",
       "      <td>0.784940</td>\n",
       "      <td>0.703704</td>\n",
       "      <td>dvlog-baseline-model-size-ablation:pt-0.25-spw...</td>\n",
       "      <td>d-vlog</td>\n",
       "      <td>test</td>\n",
       "      <td>baseline</td>\n",
       "      <td>mean</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>temporal-evaluator:dvlog-baseline-model-size-a...</td>\n",
       "      <td>temporal-evaluator</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.664000</td>\n",
       "      <td>0.805825</td>\n",
       "      <td>0.564626</td>\n",
       "      <td>0.590088</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>dvlog-baseline-model-size-ablation:pt-0.25-spw...</td>\n",
       "      <td>d-vlog</td>\n",
       "      <td>test</td>\n",
       "      <td>baseline</td>\n",
       "      <td>last</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>temporal-evaluator:dvlog-baseline-model-size-a...</td>\n",
       "      <td>temporal-evaluator</td>\n",
       "      <td>['audio_embeddings', 'face_embeddings']</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.733624</td>\n",
       "      <td>0.815534</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.762362</td>\n",
       "      <td>0.677249</td>\n",
       "      <td>dvlog-baseline-model-size-ablation:pt-0.25-spw...</td>\n",
       "      <td>d-vlog</td>\n",
       "      <td>test</td>\n",
       "      <td>baseline</td>\n",
       "      <td>mean</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>temporal-evaluator:dvlog-baseline-model-size-a...</td>\n",
       "      <td>temporal-evaluator</td>\n",
       "      <td>['audio_embeddings', 'face_embeddings']</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.733624</td>\n",
       "      <td>0.815534</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.663581</td>\n",
       "      <td>0.677249</td>\n",
       "      <td>dvlog-baseline-model-size-ablation:pt-0.25-spw...</td>\n",
       "      <td>d-vlog</td>\n",
       "      <td>test</td>\n",
       "      <td>baseline</td>\n",
       "      <td>threshold</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "      <td>temporal-evaluator:dvlog-baseline-model-size-a...</td>\n",
       "      <td>temporal-evaluator</td>\n",
       "      <td>['audio_embeddings', 'face_embeddings']</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         f1    recall  precision       auc  accuracy  \\\n",
       "0  0.590476  0.601942   0.579439  0.560962  0.544974   \n",
       "1  0.743119  0.786408   0.704348  0.784940  0.703704   \n",
       "0  0.664000  0.805825   0.564626  0.590088  0.555556   \n",
       "1  0.733624  0.815534   0.666667  0.762362  0.677249   \n",
       "2  0.733624  0.815534   0.666667  0.663581  0.677249   \n",
       "\n",
       "                                                name dataset dataset_kind  \\\n",
       "0  dvlog-baseline-model-size-ablation:pt-0.25-spw...  d-vlog         test   \n",
       "1  dvlog-baseline-model-size-ablation:pt-0.25-spw...  d-vlog         test   \n",
       "0  dvlog-baseline-model-size-ablation:pt-0.25-spw...  d-vlog         test   \n",
       "1  dvlog-baseline-model-size-ablation:pt-0.25-spw...  d-vlog         test   \n",
       "2  dvlog-baseline-model-size-ablation:pt-0.25-spw...  d-vlog         test   \n",
       "\n",
       "      model prediction_kind  ...  num_heads  head_dim  run_id  \\\n",
       "0  baseline            last  ...          8        32       2   \n",
       "1  baseline            mean  ...          8        32       2   \n",
       "0  baseline            last  ...          8        32       2   \n",
       "1  baseline            mean  ...          8        32       2   \n",
       "2  baseline       threshold  ...          8        32       2   \n",
       "\n",
       "                                            filename           evaluator  \\\n",
       "0  temporal-evaluator:dvlog-baseline-model-size-a...  temporal-evaluator   \n",
       "1  temporal-evaluator:dvlog-baseline-model-size-a...  temporal-evaluator   \n",
       "0  temporal-evaluator:dvlog-baseline-model-size-a...  temporal-evaluator   \n",
       "1  temporal-evaluator:dvlog-baseline-model-size-a...  temporal-evaluator   \n",
       "2  temporal-evaluator:dvlog-baseline-model-size-a...  temporal-evaluator   \n",
       "\n",
       "                                modalities model_args.num_layers  \\\n",
       "0                                      NaN                   NaN   \n",
       "1                                      NaN                   NaN   \n",
       "0  ['audio_embeddings', 'face_embeddings']                   8.0   \n",
       "1  ['audio_embeddings', 'face_embeddings']                   8.0   \n",
       "2  ['audio_embeddings', 'face_embeddings']                   8.0   \n",
       "\n",
       "  model_args.self_attn_num_heads model_args.self_attn_dim_head  f1_weighted  \n",
       "0                            NaN                           NaN          NaN  \n",
       "1                            NaN                           NaN          NaN  \n",
       "0                            8.0                          32.0          NaN  \n",
       "1                            8.0                          32.0          NaN  \n",
       "2                            8.0                          32.0          NaN  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_eval = dfs[dfs['evaluator'] == 'temporal-evaluator']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_eval = dfs[dfs['prediction_kind'] == 'mean']\n",
    "mean_eval = mean_eval[mean_eval['num_heads'] == 8]\n",
    "mean_eval = mean_eval[mean_eval['dataset_kind'] == 'test']\n",
    "mean_eval.sort_values(by=['seconds_per_window', 'presence_threshold', 'run_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>seconds_per_window</th>\n",
       "      <th>presence_threshold</th>\n",
       "      <th>num_layers</th>\n",
       "      <th>num_heads</th>\n",
       "      <th>head_dim</th>\n",
       "      <th>run_id</th>\n",
       "      <th colspan=\"2\" halign=\"left\">f1</th>\n",
       "      <th colspan=\"2\" halign=\"left\">precision</th>\n",
       "      <th colspan=\"2\" halign=\"left\">recall</th>\n",
       "      <th colspan=\"2\" halign=\"left\">accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.25</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>0.712833</td>\n",
       "      <td>0.066233</td>\n",
       "      <td>0.718564</td>\n",
       "      <td>0.047708</td>\n",
       "      <td>0.728155</td>\n",
       "      <td>0.163326</td>\n",
       "      <td>0.689594</td>\n",
       "      <td>0.026631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.50</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>0.708243</td>\n",
       "      <td>0.051870</td>\n",
       "      <td>0.705925</td>\n",
       "      <td>0.004090</td>\n",
       "      <td>0.715210</td>\n",
       "      <td>0.099169</td>\n",
       "      <td>0.682540</td>\n",
       "      <td>0.033042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.75</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>0.748737</td>\n",
       "      <td>0.011808</td>\n",
       "      <td>0.706449</td>\n",
       "      <td>0.057310</td>\n",
       "      <td>0.802589</td>\n",
       "      <td>0.053472</td>\n",
       "      <td>0.705467</td>\n",
       "      <td>0.038276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0.25</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>0.745678</td>\n",
       "      <td>0.018477</td>\n",
       "      <td>0.702861</td>\n",
       "      <td>0.035662</td>\n",
       "      <td>0.799353</td>\n",
       "      <td>0.072869</td>\n",
       "      <td>0.703704</td>\n",
       "      <td>0.019077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0.50</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>0.695957</td>\n",
       "      <td>0.064588</td>\n",
       "      <td>0.714293</td>\n",
       "      <td>0.058413</td>\n",
       "      <td>0.699029</td>\n",
       "      <td>0.160415</td>\n",
       "      <td>0.675485</td>\n",
       "      <td>0.035229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>0.75</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>0.752484</td>\n",
       "      <td>0.007379</td>\n",
       "      <td>0.667034</td>\n",
       "      <td>0.025983</td>\n",
       "      <td>0.867314</td>\n",
       "      <td>0.066086</td>\n",
       "      <td>0.689594</td>\n",
       "      <td>0.011014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>0.25</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>0.720157</td>\n",
       "      <td>0.048190</td>\n",
       "      <td>0.708506</td>\n",
       "      <td>0.040266</td>\n",
       "      <td>0.744337</td>\n",
       "      <td>0.123318</td>\n",
       "      <td>0.689594</td>\n",
       "      <td>0.026100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>0.50</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>0.751901</td>\n",
       "      <td>0.021258</td>\n",
       "      <td>0.670197</td>\n",
       "      <td>0.026935</td>\n",
       "      <td>0.860841</td>\n",
       "      <td>0.073513</td>\n",
       "      <td>0.691358</td>\n",
       "      <td>0.021383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>0.75</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>0.751051</td>\n",
       "      <td>0.025666</td>\n",
       "      <td>0.703550</td>\n",
       "      <td>0.023964</td>\n",
       "      <td>0.805825</td>\n",
       "      <td>0.035005</td>\n",
       "      <td>0.708995</td>\n",
       "      <td>0.029459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>0.25</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>0.746082</td>\n",
       "      <td>0.042610</td>\n",
       "      <td>0.695707</td>\n",
       "      <td>0.035194</td>\n",
       "      <td>0.805825</td>\n",
       "      <td>0.067961</td>\n",
       "      <td>0.701940</td>\n",
       "      <td>0.046227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>0.50</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>0.750279</td>\n",
       "      <td>0.031298</td>\n",
       "      <td>0.709888</td>\n",
       "      <td>0.039443</td>\n",
       "      <td>0.802589</td>\n",
       "      <td>0.092276</td>\n",
       "      <td>0.710758</td>\n",
       "      <td>0.026631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4</td>\n",
       "      <td>0.75</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>0.762660</td>\n",
       "      <td>0.012336</td>\n",
       "      <td>0.716906</td>\n",
       "      <td>0.027892</td>\n",
       "      <td>0.815534</td>\n",
       "      <td>0.016816</td>\n",
       "      <td>0.723104</td>\n",
       "      <td>0.021383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>0.726599</td>\n",
       "      <td>0.056414</td>\n",
       "      <td>0.717516</td>\n",
       "      <td>0.006869</td>\n",
       "      <td>0.741100</td>\n",
       "      <td>0.109124</td>\n",
       "      <td>0.700176</td>\n",
       "      <td>0.039001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5</td>\n",
       "      <td>0.50</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>0.734964</td>\n",
       "      <td>0.002861</td>\n",
       "      <td>0.706969</td>\n",
       "      <td>0.030121</td>\n",
       "      <td>0.766990</td>\n",
       "      <td>0.029126</td>\n",
       "      <td>0.698413</td>\n",
       "      <td>0.015873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5</td>\n",
       "      <td>0.75</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>0.731518</td>\n",
       "      <td>0.022065</td>\n",
       "      <td>0.726169</td>\n",
       "      <td>0.008064</td>\n",
       "      <td>0.737864</td>\n",
       "      <td>0.044491</td>\n",
       "      <td>0.705467</td>\n",
       "      <td>0.016164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>6</td>\n",
       "      <td>0.25</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>0.746739</td>\n",
       "      <td>0.018953</td>\n",
       "      <td>0.702411</td>\n",
       "      <td>0.011642</td>\n",
       "      <td>0.799353</td>\n",
       "      <td>0.059321</td>\n",
       "      <td>0.705467</td>\n",
       "      <td>0.008082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>6</td>\n",
       "      <td>0.50</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>0.743930</td>\n",
       "      <td>0.014426</td>\n",
       "      <td>0.739866</td>\n",
       "      <td>0.068897</td>\n",
       "      <td>0.760518</td>\n",
       "      <td>0.097249</td>\n",
       "      <td>0.716049</td>\n",
       "      <td>0.020031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6</td>\n",
       "      <td>0.75</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>0.751367</td>\n",
       "      <td>0.028589</td>\n",
       "      <td>0.731831</td>\n",
       "      <td>0.031999</td>\n",
       "      <td>0.776699</td>\n",
       "      <td>0.079469</td>\n",
       "      <td>0.721340</td>\n",
       "      <td>0.021383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>7</td>\n",
       "      <td>0.25</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>0.760204</td>\n",
       "      <td>0.021113</td>\n",
       "      <td>0.728573</td>\n",
       "      <td>0.024657</td>\n",
       "      <td>0.796117</td>\n",
       "      <td>0.044491</td>\n",
       "      <td>0.726631</td>\n",
       "      <td>0.021383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>7</td>\n",
       "      <td>0.50</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>0.745263</td>\n",
       "      <td>0.014506</td>\n",
       "      <td>0.711722</td>\n",
       "      <td>0.057901</td>\n",
       "      <td>0.789644</td>\n",
       "      <td>0.068880</td>\n",
       "      <td>0.705467</td>\n",
       "      <td>0.035229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>7</td>\n",
       "      <td>0.75</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>0.744601</td>\n",
       "      <td>0.017383</td>\n",
       "      <td>0.729757</td>\n",
       "      <td>0.002106</td>\n",
       "      <td>0.760518</td>\n",
       "      <td>0.034096</td>\n",
       "      <td>0.716049</td>\n",
       "      <td>0.013315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>8</td>\n",
       "      <td>0.25</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>0.740875</td>\n",
       "      <td>0.022391</td>\n",
       "      <td>0.711947</td>\n",
       "      <td>0.049833</td>\n",
       "      <td>0.783172</td>\n",
       "      <td>0.101052</td>\n",
       "      <td>0.703704</td>\n",
       "      <td>0.009164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>8</td>\n",
       "      <td>0.50</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>0.759512</td>\n",
       "      <td>0.012188</td>\n",
       "      <td>0.762549</td>\n",
       "      <td>0.008881</td>\n",
       "      <td>0.757282</td>\n",
       "      <td>0.033632</td>\n",
       "      <td>0.738977</td>\n",
       "      <td>0.006110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>8</td>\n",
       "      <td>0.75</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>0.763560</td>\n",
       "      <td>0.018412</td>\n",
       "      <td>0.718521</td>\n",
       "      <td>0.022514</td>\n",
       "      <td>0.818770</td>\n",
       "      <td>0.073513</td>\n",
       "      <td>0.724868</td>\n",
       "      <td>0.005291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>9</td>\n",
       "      <td>0.25</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>0.736556</td>\n",
       "      <td>0.028303</td>\n",
       "      <td>0.712012</td>\n",
       "      <td>0.037653</td>\n",
       "      <td>0.770227</td>\n",
       "      <td>0.094296</td>\n",
       "      <td>0.701940</td>\n",
       "      <td>0.017008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>9</td>\n",
       "      <td>0.50</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>0.764859</td>\n",
       "      <td>0.012449</td>\n",
       "      <td>0.703505</td>\n",
       "      <td>0.040423</td>\n",
       "      <td>0.844660</td>\n",
       "      <td>0.077061</td>\n",
       "      <td>0.717813</td>\n",
       "      <td>0.013315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>9</td>\n",
       "      <td>0.75</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>0.764474</td>\n",
       "      <td>0.019809</td>\n",
       "      <td>0.741106</td>\n",
       "      <td>0.027464</td>\n",
       "      <td>0.790850</td>\n",
       "      <td>0.040817</td>\n",
       "      <td>0.735816</td>\n",
       "      <td>0.021497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>10</td>\n",
       "      <td>0.25</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>0.752165</td>\n",
       "      <td>0.026042</td>\n",
       "      <td>0.705985</td>\n",
       "      <td>0.050541</td>\n",
       "      <td>0.815534</td>\n",
       "      <td>0.100896</td>\n",
       "      <td>0.708995</td>\n",
       "      <td>0.024246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>10</td>\n",
       "      <td>0.50</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>0.726407</td>\n",
       "      <td>0.019434</td>\n",
       "      <td>0.651993</td>\n",
       "      <td>0.058376</td>\n",
       "      <td>0.841424</td>\n",
       "      <td>0.145739</td>\n",
       "      <td>0.657848</td>\n",
       "      <td>0.026631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>10</td>\n",
       "      <td>0.75</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>0.734826</td>\n",
       "      <td>0.059037</td>\n",
       "      <td>0.718256</td>\n",
       "      <td>0.018007</td>\n",
       "      <td>0.758170</td>\n",
       "      <td>0.114891</td>\n",
       "      <td>0.707447</td>\n",
       "      <td>0.042219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   seconds_per_window presence_threshold num_layers num_heads head_dim run_id  \\\n",
       "                                                                        count   \n",
       "0                   1               0.25          8         8       32      3   \n",
       "1                   1               0.50          8         8       32      3   \n",
       "2                   1               0.75          8         8       32      3   \n",
       "3                   2               0.25          8         8       32      3   \n",
       "4                   2               0.50          8         8       32      3   \n",
       "5                   2               0.75          8         8       32      3   \n",
       "6                   3               0.25          8         8       32      3   \n",
       "7                   3               0.50          8         8       32      3   \n",
       "8                   3               0.75          8         8       32      3   \n",
       "9                   4               0.25          8         8       32      3   \n",
       "10                  4               0.50          8         8       32      3   \n",
       "11                  4               0.75          8         8       32      3   \n",
       "12                  5               0.25          8         8       32      3   \n",
       "13                  5               0.50          8         8       32      3   \n",
       "14                  5               0.75          8         8       32      3   \n",
       "15                  6               0.25          8         8       32      3   \n",
       "16                  6               0.50          8         8       32      3   \n",
       "17                  6               0.75          8         8       32      3   \n",
       "18                  7               0.25          8         8       32      3   \n",
       "19                  7               0.50          8         8       32      3   \n",
       "20                  7               0.75          8         8       32      3   \n",
       "21                  8               0.25          8         8       32      3   \n",
       "22                  8               0.50          8         8       32      3   \n",
       "23                  8               0.75          8         8       32      3   \n",
       "24                  9               0.25          8         8       32      3   \n",
       "25                  9               0.50          8         8       32      3   \n",
       "26                  9               0.75          8         8       32      3   \n",
       "27                 10               0.25          8         8       32      3   \n",
       "28                 10               0.50          8         8       32      3   \n",
       "29                 10               0.75          8         8       32      3   \n",
       "\n",
       "          f1           precision              recall            accuracy  \\\n",
       "        mean       std      mean       std      mean       std      mean   \n",
       "0   0.712833  0.066233  0.718564  0.047708  0.728155  0.163326  0.689594   \n",
       "1   0.708243  0.051870  0.705925  0.004090  0.715210  0.099169  0.682540   \n",
       "2   0.748737  0.011808  0.706449  0.057310  0.802589  0.053472  0.705467   \n",
       "3   0.745678  0.018477  0.702861  0.035662  0.799353  0.072869  0.703704   \n",
       "4   0.695957  0.064588  0.714293  0.058413  0.699029  0.160415  0.675485   \n",
       "5   0.752484  0.007379  0.667034  0.025983  0.867314  0.066086  0.689594   \n",
       "6   0.720157  0.048190  0.708506  0.040266  0.744337  0.123318  0.689594   \n",
       "7   0.751901  0.021258  0.670197  0.026935  0.860841  0.073513  0.691358   \n",
       "8   0.751051  0.025666  0.703550  0.023964  0.805825  0.035005  0.708995   \n",
       "9   0.746082  0.042610  0.695707  0.035194  0.805825  0.067961  0.701940   \n",
       "10  0.750279  0.031298  0.709888  0.039443  0.802589  0.092276  0.710758   \n",
       "11  0.762660  0.012336  0.716906  0.027892  0.815534  0.016816  0.723104   \n",
       "12  0.726599  0.056414  0.717516  0.006869  0.741100  0.109124  0.700176   \n",
       "13  0.734964  0.002861  0.706969  0.030121  0.766990  0.029126  0.698413   \n",
       "14  0.731518  0.022065  0.726169  0.008064  0.737864  0.044491  0.705467   \n",
       "15  0.746739  0.018953  0.702411  0.011642  0.799353  0.059321  0.705467   \n",
       "16  0.743930  0.014426  0.739866  0.068897  0.760518  0.097249  0.716049   \n",
       "17  0.751367  0.028589  0.731831  0.031999  0.776699  0.079469  0.721340   \n",
       "18  0.760204  0.021113  0.728573  0.024657  0.796117  0.044491  0.726631   \n",
       "19  0.745263  0.014506  0.711722  0.057901  0.789644  0.068880  0.705467   \n",
       "20  0.744601  0.017383  0.729757  0.002106  0.760518  0.034096  0.716049   \n",
       "21  0.740875  0.022391  0.711947  0.049833  0.783172  0.101052  0.703704   \n",
       "22  0.759512  0.012188  0.762549  0.008881  0.757282  0.033632  0.738977   \n",
       "23  0.763560  0.018412  0.718521  0.022514  0.818770  0.073513  0.724868   \n",
       "24  0.736556  0.028303  0.712012  0.037653  0.770227  0.094296  0.701940   \n",
       "25  0.764859  0.012449  0.703505  0.040423  0.844660  0.077061  0.717813   \n",
       "26  0.764474  0.019809  0.741106  0.027464  0.790850  0.040817  0.735816   \n",
       "27  0.752165  0.026042  0.705985  0.050541  0.815534  0.100896  0.708995   \n",
       "28  0.726407  0.019434  0.651993  0.058376  0.841424  0.145739  0.657848   \n",
       "29  0.734826  0.059037  0.718256  0.018007  0.758170  0.114891  0.707447   \n",
       "\n",
       "              \n",
       "         std  \n",
       "0   0.026631  \n",
       "1   0.033042  \n",
       "2   0.038276  \n",
       "3   0.019077  \n",
       "4   0.035229  \n",
       "5   0.011014  \n",
       "6   0.026100  \n",
       "7   0.021383  \n",
       "8   0.029459  \n",
       "9   0.046227  \n",
       "10  0.026631  \n",
       "11  0.021383  \n",
       "12  0.039001  \n",
       "13  0.015873  \n",
       "14  0.016164  \n",
       "15  0.008082  \n",
       "16  0.020031  \n",
       "17  0.021383  \n",
       "18  0.021383  \n",
       "19  0.035229  \n",
       "20  0.013315  \n",
       "21  0.009164  \n",
       "22  0.006110  \n",
       "23  0.005291  \n",
       "24  0.017008  \n",
       "25  0.013315  \n",
       "26  0.021497  \n",
       "27  0.024246  \n",
       "28  0.026631  \n",
       "29  0.042219  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_mean = mean_eval.groupby(['seconds_per_window', 'presence_threshold', 'num_layers', 'num_heads', 'head_dim']).agg(\n",
    "    {'run_id': 'count', 'f1': ['mean', 'std'], 'precision': ['mean', 'std'], 'recall': ['mean', 'std'], 'accuracy': ['mean', 'std']}).reset_index()\n",
    "grouped_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seconds_per_window</th>\n",
       "      <th>presence_threshold</th>\n",
       "      <th>num_layers</th>\n",
       "      <th>num_heads</th>\n",
       "      <th>head_dim</th>\n",
       "      <th>run_idcount</th>\n",
       "      <th>f1mean</th>\n",
       "      <th>f1std</th>\n",
       "      <th>precisionmean</th>\n",
       "      <th>precisionstd</th>\n",
       "      <th>recallmean</th>\n",
       "      <th>recallstd</th>\n",
       "      <th>accuracymean</th>\n",
       "      <th>accuracystd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>9</td>\n",
       "      <td>0.50</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>0.764859</td>\n",
       "      <td>0.012449</td>\n",
       "      <td>0.703505</td>\n",
       "      <td>0.040423</td>\n",
       "      <td>0.844660</td>\n",
       "      <td>0.077061</td>\n",
       "      <td>0.717813</td>\n",
       "      <td>0.013315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>9</td>\n",
       "      <td>0.75</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>0.764474</td>\n",
       "      <td>0.019809</td>\n",
       "      <td>0.741106</td>\n",
       "      <td>0.027464</td>\n",
       "      <td>0.790850</td>\n",
       "      <td>0.040817</td>\n",
       "      <td>0.735816</td>\n",
       "      <td>0.021497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>8</td>\n",
       "      <td>0.75</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>0.763560</td>\n",
       "      <td>0.018412</td>\n",
       "      <td>0.718521</td>\n",
       "      <td>0.022514</td>\n",
       "      <td>0.818770</td>\n",
       "      <td>0.073513</td>\n",
       "      <td>0.724868</td>\n",
       "      <td>0.005291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4</td>\n",
       "      <td>0.75</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>0.762660</td>\n",
       "      <td>0.012336</td>\n",
       "      <td>0.716906</td>\n",
       "      <td>0.027892</td>\n",
       "      <td>0.815534</td>\n",
       "      <td>0.016816</td>\n",
       "      <td>0.723104</td>\n",
       "      <td>0.021383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>7</td>\n",
       "      <td>0.25</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>0.760204</td>\n",
       "      <td>0.021113</td>\n",
       "      <td>0.728573</td>\n",
       "      <td>0.024657</td>\n",
       "      <td>0.796117</td>\n",
       "      <td>0.044491</td>\n",
       "      <td>0.726631</td>\n",
       "      <td>0.021383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>8</td>\n",
       "      <td>0.50</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>0.759512</td>\n",
       "      <td>0.012188</td>\n",
       "      <td>0.762549</td>\n",
       "      <td>0.008881</td>\n",
       "      <td>0.757282</td>\n",
       "      <td>0.033632</td>\n",
       "      <td>0.738977</td>\n",
       "      <td>0.006110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>0.75</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>0.752484</td>\n",
       "      <td>0.007379</td>\n",
       "      <td>0.667034</td>\n",
       "      <td>0.025983</td>\n",
       "      <td>0.867314</td>\n",
       "      <td>0.066086</td>\n",
       "      <td>0.689594</td>\n",
       "      <td>0.011014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>10</td>\n",
       "      <td>0.25</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>0.752165</td>\n",
       "      <td>0.026042</td>\n",
       "      <td>0.705985</td>\n",
       "      <td>0.050541</td>\n",
       "      <td>0.815534</td>\n",
       "      <td>0.100896</td>\n",
       "      <td>0.708995</td>\n",
       "      <td>0.024246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>0.50</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>0.751901</td>\n",
       "      <td>0.021258</td>\n",
       "      <td>0.670197</td>\n",
       "      <td>0.026935</td>\n",
       "      <td>0.860841</td>\n",
       "      <td>0.073513</td>\n",
       "      <td>0.691358</td>\n",
       "      <td>0.021383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6</td>\n",
       "      <td>0.75</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>0.751367</td>\n",
       "      <td>0.028589</td>\n",
       "      <td>0.731831</td>\n",
       "      <td>0.031999</td>\n",
       "      <td>0.776699</td>\n",
       "      <td>0.079469</td>\n",
       "      <td>0.721340</td>\n",
       "      <td>0.021383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>0.75</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>0.751051</td>\n",
       "      <td>0.025666</td>\n",
       "      <td>0.703550</td>\n",
       "      <td>0.023964</td>\n",
       "      <td>0.805825</td>\n",
       "      <td>0.035005</td>\n",
       "      <td>0.708995</td>\n",
       "      <td>0.029459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4</td>\n",
       "      <td>0.50</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>0.750279</td>\n",
       "      <td>0.031298</td>\n",
       "      <td>0.709888</td>\n",
       "      <td>0.039443</td>\n",
       "      <td>0.802589</td>\n",
       "      <td>0.092276</td>\n",
       "      <td>0.710758</td>\n",
       "      <td>0.026631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.75</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>0.748737</td>\n",
       "      <td>0.011808</td>\n",
       "      <td>0.706449</td>\n",
       "      <td>0.057310</td>\n",
       "      <td>0.802589</td>\n",
       "      <td>0.053472</td>\n",
       "      <td>0.705467</td>\n",
       "      <td>0.038276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>6</td>\n",
       "      <td>0.25</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>0.746739</td>\n",
       "      <td>0.018953</td>\n",
       "      <td>0.702411</td>\n",
       "      <td>0.011642</td>\n",
       "      <td>0.799353</td>\n",
       "      <td>0.059321</td>\n",
       "      <td>0.705467</td>\n",
       "      <td>0.008082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>0.25</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>0.746082</td>\n",
       "      <td>0.042610</td>\n",
       "      <td>0.695707</td>\n",
       "      <td>0.035194</td>\n",
       "      <td>0.805825</td>\n",
       "      <td>0.067961</td>\n",
       "      <td>0.701940</td>\n",
       "      <td>0.046227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0.25</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>0.745678</td>\n",
       "      <td>0.018477</td>\n",
       "      <td>0.702861</td>\n",
       "      <td>0.035662</td>\n",
       "      <td>0.799353</td>\n",
       "      <td>0.072869</td>\n",
       "      <td>0.703704</td>\n",
       "      <td>0.019077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>7</td>\n",
       "      <td>0.50</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>0.745263</td>\n",
       "      <td>0.014506</td>\n",
       "      <td>0.711722</td>\n",
       "      <td>0.057901</td>\n",
       "      <td>0.789644</td>\n",
       "      <td>0.068880</td>\n",
       "      <td>0.705467</td>\n",
       "      <td>0.035229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>7</td>\n",
       "      <td>0.75</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>0.744601</td>\n",
       "      <td>0.017383</td>\n",
       "      <td>0.729757</td>\n",
       "      <td>0.002106</td>\n",
       "      <td>0.760518</td>\n",
       "      <td>0.034096</td>\n",
       "      <td>0.716049</td>\n",
       "      <td>0.013315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>6</td>\n",
       "      <td>0.50</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>0.743930</td>\n",
       "      <td>0.014426</td>\n",
       "      <td>0.739866</td>\n",
       "      <td>0.068897</td>\n",
       "      <td>0.760518</td>\n",
       "      <td>0.097249</td>\n",
       "      <td>0.716049</td>\n",
       "      <td>0.020031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>8</td>\n",
       "      <td>0.25</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>0.740875</td>\n",
       "      <td>0.022391</td>\n",
       "      <td>0.711947</td>\n",
       "      <td>0.049833</td>\n",
       "      <td>0.783172</td>\n",
       "      <td>0.101052</td>\n",
       "      <td>0.703704</td>\n",
       "      <td>0.009164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>9</td>\n",
       "      <td>0.25</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>0.736556</td>\n",
       "      <td>0.028303</td>\n",
       "      <td>0.712012</td>\n",
       "      <td>0.037653</td>\n",
       "      <td>0.770227</td>\n",
       "      <td>0.094296</td>\n",
       "      <td>0.701940</td>\n",
       "      <td>0.017008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5</td>\n",
       "      <td>0.50</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>0.734964</td>\n",
       "      <td>0.002861</td>\n",
       "      <td>0.706969</td>\n",
       "      <td>0.030121</td>\n",
       "      <td>0.766990</td>\n",
       "      <td>0.029126</td>\n",
       "      <td>0.698413</td>\n",
       "      <td>0.015873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>10</td>\n",
       "      <td>0.75</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>0.734826</td>\n",
       "      <td>0.059037</td>\n",
       "      <td>0.718256</td>\n",
       "      <td>0.018007</td>\n",
       "      <td>0.758170</td>\n",
       "      <td>0.114891</td>\n",
       "      <td>0.707447</td>\n",
       "      <td>0.042219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5</td>\n",
       "      <td>0.75</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>0.731518</td>\n",
       "      <td>0.022065</td>\n",
       "      <td>0.726169</td>\n",
       "      <td>0.008064</td>\n",
       "      <td>0.737864</td>\n",
       "      <td>0.044491</td>\n",
       "      <td>0.705467</td>\n",
       "      <td>0.016164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5</td>\n",
       "      <td>0.25</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>0.726599</td>\n",
       "      <td>0.056414</td>\n",
       "      <td>0.717516</td>\n",
       "      <td>0.006869</td>\n",
       "      <td>0.741100</td>\n",
       "      <td>0.109124</td>\n",
       "      <td>0.700176</td>\n",
       "      <td>0.039001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>10</td>\n",
       "      <td>0.50</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>0.726407</td>\n",
       "      <td>0.019434</td>\n",
       "      <td>0.651993</td>\n",
       "      <td>0.058376</td>\n",
       "      <td>0.841424</td>\n",
       "      <td>0.145739</td>\n",
       "      <td>0.657848</td>\n",
       "      <td>0.026631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>0.25</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>0.720157</td>\n",
       "      <td>0.048190</td>\n",
       "      <td>0.708506</td>\n",
       "      <td>0.040266</td>\n",
       "      <td>0.744337</td>\n",
       "      <td>0.123318</td>\n",
       "      <td>0.689594</td>\n",
       "      <td>0.026100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.25</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>0.712833</td>\n",
       "      <td>0.066233</td>\n",
       "      <td>0.718564</td>\n",
       "      <td>0.047708</td>\n",
       "      <td>0.728155</td>\n",
       "      <td>0.163326</td>\n",
       "      <td>0.689594</td>\n",
       "      <td>0.026631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.50</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>0.708243</td>\n",
       "      <td>0.051870</td>\n",
       "      <td>0.705925</td>\n",
       "      <td>0.004090</td>\n",
       "      <td>0.715210</td>\n",
       "      <td>0.099169</td>\n",
       "      <td>0.682540</td>\n",
       "      <td>0.033042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0.50</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>0.695957</td>\n",
       "      <td>0.064588</td>\n",
       "      <td>0.714293</td>\n",
       "      <td>0.058413</td>\n",
       "      <td>0.699029</td>\n",
       "      <td>0.160415</td>\n",
       "      <td>0.675485</td>\n",
       "      <td>0.035229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    seconds_per_window  presence_threshold  num_layers  num_heads  head_dim  \\\n",
       "25                   9                0.50           8          8        32   \n",
       "26                   9                0.75           8          8        32   \n",
       "23                   8                0.75           8          8        32   \n",
       "11                   4                0.75           8          8        32   \n",
       "18                   7                0.25           8          8        32   \n",
       "22                   8                0.50           8          8        32   \n",
       "5                    2                0.75           8          8        32   \n",
       "27                  10                0.25           8          8        32   \n",
       "7                    3                0.50           8          8        32   \n",
       "17                   6                0.75           8          8        32   \n",
       "8                    3                0.75           8          8        32   \n",
       "10                   4                0.50           8          8        32   \n",
       "2                    1                0.75           8          8        32   \n",
       "15                   6                0.25           8          8        32   \n",
       "9                    4                0.25           8          8        32   \n",
       "3                    2                0.25           8          8        32   \n",
       "19                   7                0.50           8          8        32   \n",
       "20                   7                0.75           8          8        32   \n",
       "16                   6                0.50           8          8        32   \n",
       "21                   8                0.25           8          8        32   \n",
       "24                   9                0.25           8          8        32   \n",
       "13                   5                0.50           8          8        32   \n",
       "29                  10                0.75           8          8        32   \n",
       "14                   5                0.75           8          8        32   \n",
       "12                   5                0.25           8          8        32   \n",
       "28                  10                0.50           8          8        32   \n",
       "6                    3                0.25           8          8        32   \n",
       "0                    1                0.25           8          8        32   \n",
       "1                    1                0.50           8          8        32   \n",
       "4                    2                0.50           8          8        32   \n",
       "\n",
       "    run_idcount    f1mean     f1std  precisionmean  precisionstd  recallmean  \\\n",
       "25            3  0.764859  0.012449       0.703505      0.040423    0.844660   \n",
       "26            3  0.764474  0.019809       0.741106      0.027464    0.790850   \n",
       "23            3  0.763560  0.018412       0.718521      0.022514    0.818770   \n",
       "11            3  0.762660  0.012336       0.716906      0.027892    0.815534   \n",
       "18            3  0.760204  0.021113       0.728573      0.024657    0.796117   \n",
       "22            3  0.759512  0.012188       0.762549      0.008881    0.757282   \n",
       "5             3  0.752484  0.007379       0.667034      0.025983    0.867314   \n",
       "27            3  0.752165  0.026042       0.705985      0.050541    0.815534   \n",
       "7             3  0.751901  0.021258       0.670197      0.026935    0.860841   \n",
       "17            3  0.751367  0.028589       0.731831      0.031999    0.776699   \n",
       "8             3  0.751051  0.025666       0.703550      0.023964    0.805825   \n",
       "10            3  0.750279  0.031298       0.709888      0.039443    0.802589   \n",
       "2             3  0.748737  0.011808       0.706449      0.057310    0.802589   \n",
       "15            3  0.746739  0.018953       0.702411      0.011642    0.799353   \n",
       "9             3  0.746082  0.042610       0.695707      0.035194    0.805825   \n",
       "3             3  0.745678  0.018477       0.702861      0.035662    0.799353   \n",
       "19            3  0.745263  0.014506       0.711722      0.057901    0.789644   \n",
       "20            3  0.744601  0.017383       0.729757      0.002106    0.760518   \n",
       "16            3  0.743930  0.014426       0.739866      0.068897    0.760518   \n",
       "21            3  0.740875  0.022391       0.711947      0.049833    0.783172   \n",
       "24            3  0.736556  0.028303       0.712012      0.037653    0.770227   \n",
       "13            3  0.734964  0.002861       0.706969      0.030121    0.766990   \n",
       "29            3  0.734826  0.059037       0.718256      0.018007    0.758170   \n",
       "14            3  0.731518  0.022065       0.726169      0.008064    0.737864   \n",
       "12            3  0.726599  0.056414       0.717516      0.006869    0.741100   \n",
       "28            3  0.726407  0.019434       0.651993      0.058376    0.841424   \n",
       "6             3  0.720157  0.048190       0.708506      0.040266    0.744337   \n",
       "0             3  0.712833  0.066233       0.718564      0.047708    0.728155   \n",
       "1             3  0.708243  0.051870       0.705925      0.004090    0.715210   \n",
       "4             3  0.695957  0.064588       0.714293      0.058413    0.699029   \n",
       "\n",
       "    recallstd  accuracymean  accuracystd  \n",
       "25   0.077061      0.717813     0.013315  \n",
       "26   0.040817      0.735816     0.021497  \n",
       "23   0.073513      0.724868     0.005291  \n",
       "11   0.016816      0.723104     0.021383  \n",
       "18   0.044491      0.726631     0.021383  \n",
       "22   0.033632      0.738977     0.006110  \n",
       "5    0.066086      0.689594     0.011014  \n",
       "27   0.100896      0.708995     0.024246  \n",
       "7    0.073513      0.691358     0.021383  \n",
       "17   0.079469      0.721340     0.021383  \n",
       "8    0.035005      0.708995     0.029459  \n",
       "10   0.092276      0.710758     0.026631  \n",
       "2    0.053472      0.705467     0.038276  \n",
       "15   0.059321      0.705467     0.008082  \n",
       "9    0.067961      0.701940     0.046227  \n",
       "3    0.072869      0.703704     0.019077  \n",
       "19   0.068880      0.705467     0.035229  \n",
       "20   0.034096      0.716049     0.013315  \n",
       "16   0.097249      0.716049     0.020031  \n",
       "21   0.101052      0.703704     0.009164  \n",
       "24   0.094296      0.701940     0.017008  \n",
       "13   0.029126      0.698413     0.015873  \n",
       "29   0.114891      0.707447     0.042219  \n",
       "14   0.044491      0.705467     0.016164  \n",
       "12   0.109124      0.700176     0.039001  \n",
       "28   0.145739      0.657848     0.026631  \n",
       "6    0.123318      0.689594     0.026100  \n",
       "0    0.163326      0.689594     0.026631  \n",
       "1    0.099169      0.682540     0.033042  \n",
       "4    0.160415      0.675485     0.035229  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_mean.columns = grouped_mean.columns.map(''.join)\n",
    "grouped_mean.sort_values(by=['f1mean'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(labels, predictions):\n",
    "    f1 = f1_score(labels, predictions)\n",
    "    f1_weighted = f1_score(labels, predictions, average='weighted')\n",
    "    precision = precision_score(labels, predictions)\n",
    "    recall = recall_score(labels, predictions)\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "\n",
    "    return f1, f1_weighted, precision, recall, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../results/dvlog-baseline-model-size-ablation/temporal-evaluator:dvlog-baseline-model-size-ablation:pt-0.50-spw-8-nl-8-nh8-hd32-run-2:over-time:test.json\n",
      "[0 1 1 0 1 0 0 0 1 0]\n",
      "[1 1 1 0 0 0 1 1 1 1]\n",
      "[0 1 1 0 1 0 0 0 1 0]\n",
      "../results/dvlog-baseline-model-size-ablation/temporal-evaluator:dvlog-baseline-model-size-ablation:pt-0.75-spw-6-nl-8-nh8-hd32-run-1:over-time:test.json\n",
      "[0 1 1 0 1 0 1 1 1 1]\n",
      "[1 1 1 0 0 0 1 1 1 1]\n",
      "[0 1 1 0 1 0 1 1 1 1]\n",
      "../results/dvlog-baseline-model-size-ablation/temporal-evaluator:dvlog-baseline-model-size-ablation:pt-0.50-spw-5-nl-8-nh8-hd32-run-1:over-time:test.json\n",
      "[0 1 1 0 1 0 0 1 1 0]\n",
      "[1 1 1 0 0 0 1 1 1 1]\n",
      "[0 1 1 0 1 0 0 1 1 0]\n",
      "../results/dvlog-baseline-model-size-ablation/temporal-evaluator:dvlog-baseline-model-size-ablation:pt-0.25-spw-8-nl-8-nh8-hd32-run-2:over-time:test.json\n",
      "[0 1 1 0 0 0 1 1 1 0]\n",
      "[1 1 1 0 0 0 1 1 1 1]\n",
      "[0 1 1 0 0 0 1 1 1 0]\n",
      "../results/dvlog-baseline-model-size-ablation/temporal-evaluator:dvlog-baseline-model-size-ablation:pt-0.25-spw-9-nl-8-nh4-hd64-run-2:over-time:test.json\n",
      "[0 1 1 1 1 1 1 1 1 0]\n",
      "[1 1 1 0 0 0 1 1 1 1]\n",
      "[None None None None None None None None None None]\n",
      "../results/dvlog-baseline-model-size-ablation/temporal-evaluator:dvlog-baseline-model-size-ablation:pt-0.50-spw-9-nl-8-nh8-hd32-run-3:over-time:test.json\n",
      "[0 1 1 0 1 0 1 1 1 0]\n",
      "[1 1 1 0 0 0 1 1 1 1]\n",
      "[0 1 1 0 1 0 1 1 1 0]\n",
      "../results/dvlog-baseline-model-size-ablation/temporal-evaluator:dvlog-baseline-model-size-ablation:pt-0.50-spw-2-nl-8-nh8-hd32-run-1:over-time:test.json\n",
      "[0 0 0 0 1 0 0 0 1 0]\n",
      "[1 1 1 0 0 0 1 1 1 1]\n",
      "[0 0 0 0 1 0 1 0 1 0]\n",
      "../results/dvlog-baseline-model-size-ablation/temporal-evaluator:dvlog-baseline-model-size-ablation:pt-0.25-spw-10-nl-8-nh8-hd32-run-3:over-time:test.json\n",
      "[0 1 1 0 0 1 0 1 1 1]\n",
      "[1 1 1 0 0 0 1 1 1 1]\n",
      "[0 1 1 1 1 1 1 1 1 1]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of binary and unknown targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/ana/remoteDir/perceiving-depression/notebooks/evaluation.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ana/remoteDir/perceiving-depression/notebooks/evaluation.ipynb#X11sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m     f1_threshold, f1_weighted_threshold, precision_threshold, recall_threshold, accuracy_threshold \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ana/remoteDir/perceiving-depression/notebooks/evaluation.ipynb#X11sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/ana/remoteDir/perceiving-depression/notebooks/evaluation.ipynb#X11sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m     f1_threshold, f1_weighted_threshold, precision_threshold, recall_threshold, accuracy_threshold \u001b[39m=\u001b[39m compute_metrics(true_labels, y_preds_mode_threshold)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ana/remoteDir/perceiving-depression/notebooks/evaluation.ipynb#X11sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m true_labels \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([preds[key][\u001b[39m'\u001b[39m\u001b[39mtrue_label\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m sorted_keys])\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/ana/remoteDir/perceiving-depression/notebooks/evaluation.ipynb#X11sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m f1, f1_weighted, precision, recall, accuracy \u001b[39m=\u001b[39m compute_metrics(true_labels, y_preds_mode)\n",
      "\u001b[1;32m/home/ana/remoteDir/perceiving-depression/notebooks/evaluation.ipynb Cell 9\u001b[0m in \u001b[0;36mcompute_metrics\u001b[0;34m(true_labels, predictions)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ana/remoteDir/perceiving-depression/notebooks/evaluation.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute_metrics\u001b[39m(true_labels, predictions):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/ana/remoteDir/perceiving-depression/notebooks/evaluation.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     f1 \u001b[39m=\u001b[39m f1_score(true_labels, predictions)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ana/remoteDir/perceiving-depression/notebooks/evaluation.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     f1_weighted \u001b[39m=\u001b[39m f1_score(true_labels, predictions, average\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mweighted\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ana/remoteDir/perceiving-depression/notebooks/evaluation.ipynb#X11sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     precision \u001b[39m=\u001b[39m precision_score(true_labels, predictions)\n",
      "File \u001b[0;32m~/anaconda3/envs/exodus/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1123\u001b[0m, in \u001b[0;36mf1_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m    992\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mf1_score\u001b[39m(\n\u001b[1;32m    993\u001b[0m     y_true,\n\u001b[1;32m    994\u001b[0m     y_pred,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1000\u001b[0m     zero_division\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwarn\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1001\u001b[0m ):\n\u001b[1;32m   1002\u001b[0m     \u001b[39m\"\"\"Compute the F1 score, also known as balanced F-score or F-measure.\u001b[39;00m\n\u001b[1;32m   1003\u001b[0m \n\u001b[1;32m   1004\u001b[0m \u001b[39m    The F1 score can be interpreted as a harmonic mean of the precision and\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1121\u001b[0m \u001b[39m    modified with ``zero_division``.\u001b[39;00m\n\u001b[1;32m   1122\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1123\u001b[0m     \u001b[39mreturn\u001b[39;00m fbeta_score(\n\u001b[1;32m   1124\u001b[0m         y_true,\n\u001b[1;32m   1125\u001b[0m         y_pred,\n\u001b[1;32m   1126\u001b[0m         beta\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m   1127\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[1;32m   1128\u001b[0m         pos_label\u001b[39m=\u001b[39;49mpos_label,\n\u001b[1;32m   1129\u001b[0m         average\u001b[39m=\u001b[39;49maverage,\n\u001b[1;32m   1130\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m   1131\u001b[0m         zero_division\u001b[39m=\u001b[39;49mzero_division,\n\u001b[1;32m   1132\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/exodus/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1261\u001b[0m, in \u001b[0;36mfbeta_score\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1135\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfbeta_score\u001b[39m(\n\u001b[1;32m   1136\u001b[0m     y_true,\n\u001b[1;32m   1137\u001b[0m     y_pred,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     zero_division\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwarn\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1145\u001b[0m ):\n\u001b[1;32m   1146\u001b[0m     \u001b[39m\"\"\"Compute the F-beta score.\u001b[39;00m\n\u001b[1;32m   1147\u001b[0m \n\u001b[1;32m   1148\u001b[0m \u001b[39m    The F-beta score is the weighted harmonic mean of precision and recall,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1258\u001b[0m \u001b[39m    array([0.71..., 0.        , 0.        ])\u001b[39;00m\n\u001b[1;32m   1259\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1261\u001b[0m     _, _, f, _ \u001b[39m=\u001b[39m precision_recall_fscore_support(\n\u001b[1;32m   1262\u001b[0m         y_true,\n\u001b[1;32m   1263\u001b[0m         y_pred,\n\u001b[1;32m   1264\u001b[0m         beta\u001b[39m=\u001b[39;49mbeta,\n\u001b[1;32m   1265\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[1;32m   1266\u001b[0m         pos_label\u001b[39m=\u001b[39;49mpos_label,\n\u001b[1;32m   1267\u001b[0m         average\u001b[39m=\u001b[39;49maverage,\n\u001b[1;32m   1268\u001b[0m         warn_for\u001b[39m=\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39mf-score\u001b[39;49m\u001b[39m\"\u001b[39;49m,),\n\u001b[1;32m   1269\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m   1270\u001b[0m         zero_division\u001b[39m=\u001b[39;49mzero_division,\n\u001b[1;32m   1271\u001b[0m     )\n\u001b[1;32m   1272\u001b[0m     \u001b[39mreturn\u001b[39;00m f\n",
      "File \u001b[0;32m~/anaconda3/envs/exodus/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1544\u001b[0m, in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1542\u001b[0m \u001b[39mif\u001b[39;00m beta \u001b[39m<\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1543\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mbeta should be >=0 in the F-beta score\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1544\u001b[0m labels \u001b[39m=\u001b[39m _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n\u001b[1;32m   1546\u001b[0m \u001b[39m# Calculate tp_sum, pred_sum, true_sum ###\u001b[39;00m\n\u001b[1;32m   1547\u001b[0m samplewise \u001b[39m=\u001b[39m average \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39msamples\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/exodus/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1348\u001b[0m, in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1345\u001b[0m \u001b[39mif\u001b[39;00m average \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m average_options \u001b[39mand\u001b[39;00m average \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m   1346\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39maverage has to be one of \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(average_options))\n\u001b[0;32m-> 1348\u001b[0m y_type, y_true, y_pred \u001b[39m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[1;32m   1349\u001b[0m \u001b[39m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[39;00m\n\u001b[1;32m   1350\u001b[0m \u001b[39m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[39;00m\n\u001b[1;32m   1351\u001b[0m present_labels \u001b[39m=\u001b[39m unique_labels(y_true, y_pred)\u001b[39m.\u001b[39mtolist()\n",
      "File \u001b[0;32m~/anaconda3/envs/exodus/lib/python3.8/site-packages/sklearn/metrics/_classification.py:93\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     90\u001b[0m     y_type \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m}\n\u001b[1;32m     92\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(y_type) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m---> 93\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     94\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mClassification metrics can\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt handle a mix of \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m targets\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m     95\u001b[0m             type_true, type_pred\n\u001b[1;32m     96\u001b[0m         )\n\u001b[1;32m     97\u001b[0m     )\n\u001b[1;32m     99\u001b[0m \u001b[39m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[1;32m    100\u001b[0m y_type \u001b[39m=\u001b[39m y_type\u001b[39m.\u001b[39mpop()\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and unknown targets"
     ]
    }
   ],
   "source": [
    "json_preds_files = glob.glob('../results/dvlog-baseline-model-size-ablation/*over-time:test.json')\n",
    "\n",
    "json_preds = []\n",
    "\n",
    "for file in json_preds_files:\n",
    "    print(file)\n",
    "    preds = defaultdict(lambda: {'mode_preds': None, 'mode_preds_threshold': None, 'true_label': None})\n",
    "\n",
    "    with open(file) as f:\n",
    "        preds_over_time = json.load(f)\n",
    "    \n",
    "    for key in preds_over_time.keys():\n",
    "        if 'pred' in key:\n",
    "            continue\n",
    "\n",
    "        preds[key]['mode_preds'] = int(mode(np.round(preds_over_time[key]['preds']))[0][0])\n",
    "\n",
    "        if 'preds_threshold' in preds_over_time[key].keys() and len(preds_over_time[key]['preds_threshold']) > 0:\n",
    "            preds[key]['mode_preds_threshold'] = int(mode(np.round(preds_over_time[key]['preds_threshold']))[0][0])\n",
    "\n",
    "        preds[key]['true_label'] = int(preds_over_time[key]['true_label'])\n",
    "\n",
    "    sorted_keys = sorted(preds.keys())\n",
    "\n",
    "    y_preds_mode = np.array([preds[key]['mode_preds'] for key in sorted_keys])\n",
    "    true_labels = np.array([preds[key]['true_label'] for key in sorted_keys])\n",
    "\n",
    "    print(y_preds_mode[:10])\n",
    "    print(true_labels[:10])\n",
    "    y_preds_mode_threshold = np.array([preds[key]['mode_preds_threshold'] for key in sorted_keys])\n",
    "    print(y_preds_mode_threshold[:10])\n",
    "\n",
    "    if y_preds_mode_threshold[0] == None:\n",
    "        f1_threshold, f1_weighted_threshold, precision_threshold, recall_threshold, accuracy_threshold = 0, 0, 0, 0, 0\n",
    "    \n",
    "    else:\n",
    "        f1_threshold, f1_weighted_threshold, precision_threshold, recall_threshold, accuracy_threshold = compute_metrics(true_labels, y_preds_mode_threshold)\n",
    "\n",
    "    true_labels = np.array([preds[key]['true_label'] for key in sorted_keys])\n",
    "\n",
    "    f1, f1_weighted, precision, recall, accuracy = compute_metrics(true_labels, y_preds_mode)\n",
    "    \n",
    "    results = {\n",
    "        'seconds_per_window': [int(file.split(':')[-3].split('-')[3])] * 2,\n",
    "        'presence_threshold': [float(file.split(':')[-3].split('-')[1])] * 2,\n",
    "        'num_layers': [int(file.split(':')[-3].split('-')[5])] * 2,\n",
    "        'num_heads': [int(file.split(':')[-3].split('-')[6][-1:])] * 2,\n",
    "        'head_dim': [int(file.split(':')[-3].split('-')[7][-2:])] * 2,\n",
    "        'run_id': [int(file.split(':')[-3].split('-')[9])] * 2,\n",
    "        'filename': [file.split('/')[-1]] * 2,\n",
    "        'evaluator': [file.split('/')[-1].split(':')[0]] * 2,\n",
    "        'f1': [f1, f1_threshold],\n",
    "        'f1_weighted': [f1_weighted, f1_weighted_threshold],\n",
    "        'precision': [precision, precision_threshold],\n",
    "        'recall': [recall, recall_threshold],\n",
    "        'accuracy': [accuracy, accuracy_threshold],\n",
    "        'prediction_kind': ['mode', 'mode_threshold'],\n",
    "\n",
    "    }\n",
    "\n",
    "    results = pd.DataFrame.from_dict(results)\n",
    "    json_preds.append(results)\n",
    "\n",
    "json_all_preds = pd.concat(json_preds)\n",
    "json_all_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exodus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
